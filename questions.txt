Responda às seguintes questões de forma discursiva:

1 - Agora você tem de capturar dados de outros 100 sites. Quais seriam suas estratégias para escalar a aplicação?
	
	Tentaria identificar padrões no site e usar alguns recursos de NLP para pegar as informações de forma mais genérica, sem necessariamente aplicar a xpath para cada site. Para escalar o crawler, iria fazer uma "Conteinerização" do meu crawler para que pudesse colocar em vários servidores diferentes.

2 - Alguns sites carregam o preço através de JavaScript. Como faria para capturar esse valor.

	Podemos terceirizar a tarefa de renderizar a página inteira em um navegador da web. Então, em vez de usar o HTML baixado pelo Python, vamos fazer um navegador baixar a página e executar o código JS para nós e entregar a resposta pronta do HTML. Uma opção legal para isso é o PhantomJS, que é um navegador sem header e pode ser facilmente integrado ao Python via Selenium.

3 - Alguns sites podem bloquear a captura por interpretar seus acessos como um ataque DDOS. Como lidaria com essa situação?
	
	Uma alternativa seria usar um proxy, colocando várias máquinas com diferentes IP's e um proxy para ficar alternando a máquina que acessa o recurso.

	Uma outra forma é a taxa do loop usando a função sleep() do módulo de tempo do Python. sleep() interromperá a execução do loop por um período especificado de segundos para imitar o comportamento humano gera aleatoriamente números de requisições.

4 - Um cliente liga reclamando que está fazendo muitos acessos ao seu site e aumentando seus custos com infra. Como resolveria esse problema?

	Uma solução seria aumentar o delay entre as requisições e verificar quais urls podem ter um gap maior entre os acessos, para não precisar várias vezese a